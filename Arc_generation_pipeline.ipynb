{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506b6c5c",
   "metadata": {},
   "source": [
    "# Routing Optimization Capstone Project  - optimizaiton material generation pipeline\n",
    "\n",
    "Project student team: Peter Pan; Vincent Pan; Sanjit Sokhi, Jerry Wang, Jiadi Zhang\n",
    "\n",
    "Advisor: Amr Farahat\n",
    "\n",
    "Creation date: 2023-04-01\n",
    "\n",
    "This notebook generates the necessary arcs and nodes for the network flow optimization base upon 1) drivers' home location, 2) jobs' origin and destination location, 3) the time windows for pickups and deliveries. The next jupyter notebook for the optimization model reads the materials generated by this notebook and performs the optimization.\n",
    "To protect the company's information, the data used in this notebook is completed simulated.\n",
    "The materials are generated in the form of a pickle file. \n",
    "You can glimpse the sample materials at the bottom of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67424701",
   "metadata": {},
   "source": [
    "Choose the number of drivers and number of orders you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "d937e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_driver =  30\n",
    "num_order = 150\n",
    "random_state_param = 886\n",
    "#mip_gap = 0.05  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cdc36",
   "metadata": {},
   "source": [
    " ## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "9cbb0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim \n",
    "from geopy import distance \n",
    "from multidict import MultiDict\n",
    "import math\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd561f4c",
   "metadata": {},
   "source": [
    " ## Setting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff2f4a",
   "metadata": {},
   "source": [
    "Distance functions to calculate the distance between two areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "17717e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_distance(origin_zip,dest_zip):\n",
    "    geolocator = Nominatim(user_agent = \"my_app_name\")\n",
    "    origin_loc = geolocator.geocode(origin_zip,country_codes ='us')\n",
    "    dest_loc = geolocator.geocode(dest_zip,country_codes ='us')\n",
    "    origin_latlon = (origin_loc.latitude,origin_loc.longitude)\n",
    "    dest_latlon = (dest_loc.latitude,dest_loc.longitude)\n",
    "    return (distance.distance(origin_latlon,dest_latlon).miles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "4267b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    try:\n",
    "        R = 6371  # radius of the Earth in kilometers\n",
    "        dlon = math.radians(lon2 - lon1)\n",
    "        dlat = math.radians(lat2 - lat1)\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        return R * c /1.609\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9267373",
   "metadata": {},
   "source": [
    "Time function to calcualte the time consumption for a trucker to travel certain dsitance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "bf99780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_time(dis):\n",
    "    speed = 7.6 * math.log(dis) + 4.5\n",
    "    time_consumption = dis/speed\n",
    "    return time_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b59dcf",
   "metadata": {},
   "source": [
    "Function to standardize zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "8f6b0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_correcter(zipcodes):\n",
    "    zipdf = zipcodes.copy()\n",
    "    corrected_zips = []\n",
    "    for azip in zipdf:\n",
    "        zip_length = len(str(azip))\n",
    "        if zip_length < 5:\n",
    "            corrected_zips.append((5-zip_length)*'0' + str(azip))\n",
    "        elif zip_length > 5:\n",
    "            corrected_zips.append(str(azip)[:5])\n",
    "        else:\n",
    "            corrected_zips.append(azip)\n",
    "    return corrected_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc357470",
   "metadata": {},
   "source": [
    " ## importing and processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf6f0d",
   "metadata": {},
   "source": [
    "Data import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "93271b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/simulated_order_sample.csv\",dtype={'dest_zipcode':str,'origin_zipcode':str})\n",
    "df['dest_zipcode'] = zip_correcter(df['dest_zipcode'])\n",
    "df['origin_zipcode'] = zip_correcter(df['origin_zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "e0a292fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna().sample(num_order, random_state = random_state_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "8588c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['origin_zipcode'] = df2['origin_zipcode'].astype(str)\n",
    "df2['dest_zipcode'] = df2['dest_zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c261534",
   "metadata": {},
   "source": [
    "Creating pickup_midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "a9ad2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns pick_up_midpoint\n",
    "from datetime import datetime\n",
    "df2['pickup_start_date_time'] = df2.apply(lambda row: datetime.strptime(row['pickup_window_start'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['pickup_end_date_time'] = df2.apply(lambda row: datetime.strptime(row['pickup_window_end'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['pickup_midpoint'] = df2.apply(lambda row: row['pickup_start_date_time'] + (row['pickup_end_date_time'] - row['pickup_start_date_time']) / 2,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d2518",
   "metadata": {},
   "source": [
    "Creating Delivery_midpoint time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "000c0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns delivery midpoints\n",
    "df2['delivery_start_date_time'] = df2.apply(lambda row: datetime.strptime(row['delivery_window_start'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['delivery_end_date_time'] = df2.apply(lambda row: datetime.strptime(row['delivery_window_end'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['delivery_midpoint'] = df2.apply(lambda row: row['delivery_start_date_time'] + (row['delivery_end_date_time'] - row['delivery_start_date_time']) / 2,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d834eae4",
   "metadata": {},
   "source": [
    "Assuming that the drivers start working at 6am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "e4456e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays = []\n",
    "import datetime\n",
    "#Computing the mondays 6am of the weeks that the jobs are in\n",
    "for ts in df2['pickup_midpoint']:\n",
    "    # convert to datetime object\n",
    "    dt = ts.to_pydatetime()\n",
    "\n",
    "    # get the date and weekday\n",
    "    date = dt.date()\n",
    "    weekday = date.weekday()\n",
    "\n",
    "    # calculate timedelta to previous Monday\n",
    "    days_to_subtract = (7 + weekday) % 7\n",
    "    monday = date - datetime.timedelta(days=days_to_subtract)\n",
    "\n",
    "    # set hour and minute\n",
    "    monday = datetime.datetime.combine(monday, datetime.time(hour=6, minute=0))\n",
    "\n",
    "    # convert back to timestamp object\n",
    "    monday = pd.Timestamp(monday)\n",
    "\n",
    "    mondays.append(monday)\n",
    "\n",
    "mondays  # output: [Timestamp('2023-03-06 06:00:00'),\n",
    "\n",
    "df2['monday_6am'] = mondays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "2377d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_arrive(mid_point):\n",
    "    time_available = max(mid_point.weekday()-1, 0)*12 + mid_point.hour-6 + mid_point.minute/60\n",
    "    return time_available\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8a9e1",
   "metadata": {},
   "source": [
    "Computing whether the driver could arrive to the job if they begin driving at 6am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "789295b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the time difference between monday 6am and the pickup_midpoint time\n",
    "df2['driver_home_to_job_midpoint_time_limit'] = df2.apply(lambda row : time_to_arrive(row['pickup_midpoint']),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc50c83",
   "metadata": {},
   "source": [
    "Importing drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "c304d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross merging driver sample and job dataframe\n",
    "md = pd.read_csv('C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/simulated_driver_sample.csv', dtype={'depot_zipcode':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "99b1d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "md['depot_zipcode'] = zip_correcter(md['depot_zipcode'])\n",
    "ds = md.sample(num_driver, random_state = random_state_param)\n",
    "ds['key']=1\n",
    "df2['key']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1db95",
   "metadata": {},
   "source": [
    "Creating terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "d193c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning terminals to drivers\n",
    "terminals = []\n",
    "\n",
    "for i in range (0,len(ds)):\n",
    "    terminals.append(str('T'+str(i)))\n",
    "\n",
    "ds['terminals'] = terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac2e61",
   "metadata": {},
   "source": [
    "Merging drivers and orders to compute all driver-to-order possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "ba2d8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame = pd.merge(ds,df2, on = 'key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "b72f8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = pd.read_csv('uszips.csv', dtype={'zip':str})\n",
    "zips['zip'] = zip_correcter(zips['zip'])\n",
    "zips['zip'] = zips['zip'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c37b38",
   "metadata": {},
   "source": [
    "Examine how many driver zip codes are not included in the zip code profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "e7912aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zips['zip'][zips['zip'].isin(big_frame['depot_zipcode'])]) - len(big_frame['depot_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "beba0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame['origin_zipcode'] = big_frame['origin_zipcode'].astype(str)\n",
    "big_frame['dest_zipcode'] = big_frame['dest_zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1b52d",
   "metadata": {},
   "source": [
    "Examine how many order zip codes are not included in the zip code profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "b3b9383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zips['zip'][zips['zip'].isin(big_frame['origin_zipcode'])]\n",
    "len(zips['zip'][zips['zip'].isin(big_frame['origin_zipcode'])]) - len(big_frame['origin_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "b8b47ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zips['zip'][zips['zip'].isin(big_frame['dest_zipcode'])]) - len(big_frame['dest_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "554f437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame['dest_zipcode'][~big_frame['dest_zipcode'].isin(zips['zip'])].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "ced569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips.columns = ['zip','depot_lat','depot_lng']\n",
    "bigger_frame = pd.merge(zips,big_frame, left_on = 'zip', right_on = 'depot_zipcode')\n",
    "zips.columns = ['zip','origin_lat','origin_lng']\n",
    "bigger_bigger_frame = pd.merge(zips,bigger_frame, left_on = 'zip', right_on = 'origin_zipcode')\n",
    "zips.columns = ['zip','dest_lat','dest_lng']\n",
    "biggest_frame = pd.merge(zips, bigger_bigger_frame, left_on = 'zip', right_on = 'dest_zipcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2068a0",
   "metadata": {},
   "source": [
    "Computing driver to job distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "c01eabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['depot_lng'],row['depot_lat'],row['origin_lng'],row['origin_lat']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "a6123f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_verification_sample = biggest_frame.sample(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb4d5d",
   "metadata": {},
   "source": [
    "Examining the validity of haversine distance. The examination costs time, so let the codes be commented out if not examining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "c35f8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "49ffa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['haversine_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['origin_lng'],row['origin_lat'],row['dest_lng'],row['dest_lat']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "5be370a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = pd.DataFrame((biggest_frame['haversine_distance'].drop_duplicates()-biggest_frame['DispatchMiles'].drop_duplicates())/biggest_frame['DispatchMiles'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "f4a281ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19.925135\n",
       "dtype: float64"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "5d628b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_distance_plus'] = biggest_frame['driver_to_job_distance'] + biggest_frame['haversine_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "9fa89572",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_time'] = biggest_frame['driver_to_job_distance_plus'] .apply(lambda row: my_time(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "201a3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the feasible 1st jobs. If a job cannot be done on the first wave of driver's after 6am on Monday, the jobs cannot be done\n",
    "first_wave = biggest_frame[biggest_frame['driver_to_job_time'] < biggest_frame['driver_home_to_job_midpoint_time_limit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "e7b7b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_wave = first_wave[first_wave['driver_to_job_distance']>0]\n",
    "first_wave = first_wave.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "911d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_to_order = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    driver_to_order[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "7315be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['job_to_driver_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['origin_lng'], row['origin_lat'], row['depot_lng'], row['depot_lat']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "a97d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_day = []\n",
    "for index, row in df2.iterrows():\n",
    "    if row['delivery_start_date_time'].day != row['delivery_end_date_time'].day:\n",
    "        equal_day.append('1')\n",
    "    else:\n",
    "        equal_day.append('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "d557330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['same_day'] = equal_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d216c81",
   "metadata": {},
   "source": [
    "Examining the computed midpoint time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "dd3e99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in df2[df2['same_day']=='1'].iterrows():\n",
    " #   print(row['delivery_start_date_time'], row['delivery_start_date_time'] + (row['delivery_end_date_time'] - row['delivery_start_date_time']) /2, row['delivery_end_date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "4f9cc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['delivery_midpoint'] = df2['delivery_start_date_time'] + (df2['delivery_end_date_time'] - df2['delivery_start_date_time']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "de14b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pickup_midpoint'] = df2['pickup_start_date_time'] + (df2['pickup_end_date_time'] - df2['pickup_start_date_time']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "01acc187",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips.columns = ['zip','origin_lat','origin_lng']\n",
    "df2 = pd.merge(df2, zips, right_on = 'zip', left_on = 'origin_zipcode', how = 'left')\n",
    "zips.columns = ['zip','dest_lat','dest_lng']\n",
    "df2 = pd.merge(df2, zips, right_on = 'zip', left_on = 'dest_zipcode', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "733efbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "a3f6f6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_zipcode</th>\n",
       "      <th>dest_zipcode</th>\n",
       "      <th>pickup_window_start</th>\n",
       "      <th>pickup_window_end</th>\n",
       "      <th>delivery_window_start</th>\n",
       "      <th>delivery_window_end</th>\n",
       "      <th>LineHaulRevenue</th>\n",
       "      <th>DispatchMiles</th>\n",
       "      <th>...</th>\n",
       "      <th>monday_6am</th>\n",
       "      <th>driver_home_to_job_midpoint_time_limit</th>\n",
       "      <th>key</th>\n",
       "      <th>same_day</th>\n",
       "      <th>zip_x</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lng</th>\n",
       "      <th>zip_y</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, order_id, origin_zipcode, dest_zipcode, pickup_window_start, pickup_window_end, delivery_window_start, delivery_window_end, LineHaulRevenue, DispatchMiles, hour_difference, pickup_start_date_time, pickup_end_date_time, pickup_midpoint, delivery_start_date_time, delivery_end_date_time, delivery_midpoint, monday_6am, driver_home_to_job_midpoint_time_limit, key, same_day, zip_x, origin_lat, origin_lng, zip_y, dest_lat, dest_lng]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['order_id'] == 3786037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "c00971f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_zipcode</th>\n",
       "      <th>dest_zipcode</th>\n",
       "      <th>pickup_window_start</th>\n",
       "      <th>pickup_window_end</th>\n",
       "      <th>delivery_window_start</th>\n",
       "      <th>delivery_window_end</th>\n",
       "      <th>LineHaulRevenue</th>\n",
       "      <th>DispatchMiles</th>\n",
       "      <th>...</th>\n",
       "      <th>monday_6am</th>\n",
       "      <th>driver_home_to_job_midpoint_time_limit</th>\n",
       "      <th>key</th>\n",
       "      <th>same_day</th>\n",
       "      <th>zip_x</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lng</th>\n",
       "      <th>zip_y</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, order_id, origin_zipcode, dest_zipcode, pickup_window_start, pickup_window_end, delivery_window_start, delivery_window_end, LineHaulRevenue, DispatchMiles, hour_difference, pickup_start_date_time, pickup_end_date_time, pickup_midpoint, delivery_start_date_time, delivery_end_date_time, delivery_midpoint, monday_6am, driver_home_to_job_midpoint_time_limit, key, same_day, zip_x, origin_lat, origin_lng, zip_y, dest_lat, dest_lng]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 27 columns]"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['order_id'] == 3786037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "e149f9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index_x', 'order_id_x', 'origin_zipcode_x', 'dest_zipcode_x',\n",
       "       'pickup_window_start_x', 'pickup_window_end_x',\n",
       "       'delivery_window_start_x', 'delivery_window_end_x', 'LineHaulRevenue_x',\n",
       "       'DispatchMiles_x', 'hour_difference_x', 'pickup_start_date_time_x',\n",
       "       'pickup_end_date_time_x', 'pickup_midpoint_x',\n",
       "       'delivery_start_date_time_x', 'delivery_end_date_time_x',\n",
       "       'delivery_midpoint_x', 'monday_6am_x',\n",
       "       'driver_home_to_job_midpoint_time_limit_x', 'key', 'same_day_x',\n",
       "       'zip_x_x', 'origin_lat_x', 'origin_lng_x', 'zip_y_x', 'dest_lat_x',\n",
       "       'dest_lng_x', 'index_y', 'order_id_y', 'origin_zipcode_y',\n",
       "       'dest_zipcode_y', 'pickup_window_start_y', 'pickup_window_end_y',\n",
       "       'delivery_window_start_y', 'delivery_window_end_y', 'LineHaulRevenue_y',\n",
       "       'DispatchMiles_y', 'hour_difference_y', 'pickup_start_date_time_y',\n",
       "       'pickup_end_date_time_y', 'pickup_midpoint_y',\n",
       "       'delivery_start_date_time_y', 'delivery_end_date_time_y',\n",
       "       'delivery_midpoint_y', 'monday_6am_y',\n",
       "       'driver_home_to_job_midpoint_time_limit_y', 'same_day_y', 'zip_x_y',\n",
       "       'origin_lat_y', 'origin_lng_y', 'zip_y_y', 'dest_lat_y', 'dest_lng_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.merge(df2, df2, on = 'key')\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "e35e12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['inter_job_distance'] = df3.apply(lambda row: haversine_distance(row['dest_lng_x'],row['dest_lat_x'],row['origin_lng_y'],row['origin_lat_y']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "3d5d4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[df3['inter_job_distance'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "5a009403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['inter_job_distance'].apply(lambda row: my_time(row))\n",
    "inter_job_time = []\n",
    "for index, row in df3.iterrows():\n",
    "    inter_job_time.append(my_time(row['inter_job_distance']))\n",
    "df3['inter_job_time'] = inter_job_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "bed9f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['inter_job_time_limit'] = (df3['pickup_midpoint_y'] - df3['delivery_midpoint_x']).astype('timedelta64[h]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "3b39b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[df3['inter_job_time'] < df3['inter_job_time_limit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99188aeb",
   "metadata": {},
   "source": [
    " ## Creating arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "9986896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f51ff",
   "metadata": {},
   "source": [
    "Purple arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "724853dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_wave = first_wave.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "id": "b6c3eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_out_arcs = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    purple_out_arcs[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "1a14dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_out_flow_arcs = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['driver_id']),str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    purple_out_flow_arcs[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "id": "ca3d1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_in_arcs = {}\n",
    "\n",
    "for i in range(0,len(first_wave)):\n",
    "    purple_in_arcs[(str(str(first_wave['order_id'][i])),first_wave['terminals'][i])] = my_time(first_wave[\"driver_to_job_distance\"][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "id": "0d8f7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_in_flow_arcs = {}\n",
    "\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['driver_id']), str(row['order_id']), str(row['terminals']))\n",
    "    value = my_time(row[\"driver_to_job_distance\"])\n",
    "    purple_in_flow_arcs[key] = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a693ae",
   "metadata": {},
   "source": [
    "green arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "048e3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "0e05257d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4['second_job_distance'] = df4.apply(lambda row: haversine_distance(row['dest_lng_y'], row['dest_lat_y'], row['origin_lng_y'], row['origin_lat_y']),axis = 1)\n",
    "df5 = df4[df4['second_job_distance'] > 0]\n",
    "df5['second_job_time'] = df5['second_job_distance'].apply(lambda row: my_time(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "bb70349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['green_arc_time'] = df5['second_job_time']+df5['inter_job_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "423fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.reset_index()\n",
    "green_arcs = {}\n",
    "\n",
    "for i in range(0,len(df5)):\n",
    "    green_arcs[str(df5['order_id_x'][i]),str(df5[\"order_id_y\"][i])] = df5[\"green_arc_time\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "c3805f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[['order_id_x','order_id_y','green_arc_time']]\n",
    "df7 = first_wave[['driver_id','order_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "dc25f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.merge(df6,df7,left_on = 'order_id_x', right_on = 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "f9980e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df8.reset_index()\n",
    "green_flow_arcs = {}\n",
    "\n",
    "for i in range(0,len(df8 )):\n",
    "    green_flow_arcs[str(df8['driver_id'][i]), str(df8['order_id_x'][i]),str(df8[\"order_id_y\"][i])] = df8[\"green_arc_time\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2dd9c",
   "metadata": {},
   "source": [
    "terminals, drivers, and orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "5eee491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29607\n",
      "2612\n",
      "2800\n",
      "2800\n",
      "2800\n",
      "2800\n"
     ]
    }
   ],
   "source": [
    "print(len(green_flow_arcs))\n",
    "print(len(green_arcs))\n",
    "print(len(purple_out_flow_arcs))\n",
    "print(len(purple_out_arcs))\n",
    "print(len(purple_in_arcs))\n",
    "print(len(purple_in_flow_arcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "f8622ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arcs = {}\n",
    "all_arcs.update(purple_out_arcs)\n",
    "all_arcs.update(purple_in_arcs)\n",
    "all_arcs.update(green_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "66bf6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_arcs = {}\n",
    "flow_arcs.update(purple_out_flow_arcs)\n",
    "flow_arcs.update(purple_in_flow_arcs)\n",
    "flow_arcs.update(green_flow_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "7a164b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_revenues = {}\n",
    "\n",
    "for i in range(0,len(df2)):\n",
    "    jobs_revenues[str(df2['order_id'][i])] = df2[\"LineHaulRevenue\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "8b9ce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = list(ds['driver_id'])\n",
    "jobs = list(df2['order_id'].astype(str))\n",
    "nodes = terminals + jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "7ebedcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data_set = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "2c59c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_materials = (terminals, drivers, jobs, nodes, jobs_revenues, all_arcs, flow_arcs, order_data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "cf834b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T0', 'T1', 'T2', 'T3', 'T4', 'T5']\n",
      "['Driver286', 'Driver223', 'Driver311', 'Driver458', 'Driver378', 'Driver247']\n",
      "['3305', '476', '4911', '9245', '1438', '3850']\n",
      "['T0', 'T1', 'T2', 'T3', 'T4', 'T5']\n",
      "{'3305': 2778.652284813813, '476': 5112.505514467786, '4911': 1427.9496197121769, '9245': 5165.814081230233, '1438': 1490.0483507566723, '3850': 3843.1429844719055}\n",
      "{('T17', '2363'): 28.437503646537525, ('T29', '2363'): 27.330132230242057, ('T22', '2363'): 23.613028522995, ('T20', '2363'): 26.15496421823642, ('T25', '2363'): 27.20856293091873, ('T0', '2363'): 34.766723710145314}\n",
      "{('Driver41', 'T17', '2363'): 28.437503646537525, ('Driver331', 'T29', '2363'): 27.330132230242057, ('Driver91', 'T22', '2363'): 23.613028522995, ('Driver228', 'T20', '2363'): 26.15496421823642, ('Driver344', 'T25', '2363'): 27.20856293091873, ('Driver286', 'T0', '2363'): 34.766723710145314}\n"
     ]
    }
   ],
   "source": [
    "for obj in model_materials[:7]:\n",
    "    if isinstance(obj, dict):\n",
    "        first_five_items = {k: obj[k] for k in list(obj.keys())[:6]}\n",
    "    else:\n",
    "        first_five_items = obj[:6]\n",
    "    print(first_five_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "id": "bbafdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/model_materials.pkl', 'wb') as f:\n",
    "    pickle.dump(model_materials, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
