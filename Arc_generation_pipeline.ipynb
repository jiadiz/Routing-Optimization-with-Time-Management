{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506b6c5c",
   "metadata": {},
   "source": [
    "# Routing Optimization Capstone Project  - optimization material generation pipeline\n",
    "\n",
    "Project student team: Peter Pan; Vincent Pan; Sanjit Sokhi, Jerry Wang, Jiadi Zhang\n",
    "\n",
    "Advisor: Amr Farahat\n",
    "\n",
    "Creation date: 2023-04-01\n",
    "\n",
    "This notebook translates raw data into optimizable format.\n",
    "The arcs and nodes for the network flow optimization base upon 1) drivers' home location, 2) jobs' origin and destination location, 3) the time windows for pickups and deliveries. The next jupyter notebook for the optimization model reads the materials generated by this notebook and performs the optimization.\n",
    "To protect the company's information, the data used in this notebook is completed simulated.\n",
    "The materials are generated in the form of a pickle file. \n",
    "You can glimpse the sample materials at the bottom of the page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67424701",
   "metadata": {},
   "source": [
    "Choose the number of drivers and number of orders you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d937e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_driver =  30\n",
    "num_order = 500\n",
    "random_state_param = 886\n",
    "#mip_gap = 0.05  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cdc36",
   "metadata": {},
   "source": [
    " ## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9cbb0d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from geopy.geocoders import Nominatim \n",
    "from geopy import distance \n",
    "from multidict import MultiDict\n",
    "import math\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd561f4c",
   "metadata": {},
   "source": [
    " ## Setting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff2f4a",
   "metadata": {},
   "source": [
    "Distance functions to calculate the distance between two areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "17717e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_distance(origin_zip,dest_zip):\n",
    "    geolocator = Nominatim(user_agent = \"my_app_name\")\n",
    "    origin_loc = geolocator.geocode(origin_zip,country_codes ='us')\n",
    "    dest_loc = geolocator.geocode(dest_zip,country_codes ='us')\n",
    "    origin_latlon = (origin_loc.latitude,origin_loc.longitude)\n",
    "    dest_latlon = (dest_loc.latitude,dest_loc.longitude)\n",
    "    return (distance.distance(origin_latlon,dest_latlon).miles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4267b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    try:\n",
    "        R = 6371  # radius of the Earth in kilometers\n",
    "        dlon = math.radians(lon2 - lon1)\n",
    "        dlat = math.radians(lat2 - lat1)\n",
    "        a = math.sin(dlat / 2) ** 2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        return R * c /1.609\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9267373",
   "metadata": {},
   "source": [
    "Time function to calcualte the time consumption for a trucker to travel certain dsitance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bf99780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_time(dis):\n",
    "    speed = 7.6 * math.log(dis) + 4.5\n",
    "    time_consumption = dis/speed\n",
    "    return time_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b59dcf",
   "metadata": {},
   "source": [
    "Function to standardize zip codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f6b0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_correcter(zipcodes):\n",
    "    zipdf = zipcodes.copy()\n",
    "    corrected_zips = []\n",
    "    for azip in zipdf:\n",
    "        zip_length = len(str(azip))\n",
    "        if zip_length < 5:\n",
    "            corrected_zips.append((5-zip_length)*'0' + str(azip))\n",
    "        elif zip_length > 5:\n",
    "            corrected_zips.append(str(azip)[:5])\n",
    "        else:\n",
    "            corrected_zips.append(azip)\n",
    "    return corrected_zips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc357470",
   "metadata": {},
   "source": [
    " ## importing and processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaf6f0d",
   "metadata": {},
   "source": [
    "Data import section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "93271b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/simulated_order_sample.csv\",dtype={'dest_zipcode':str,'origin_zipcode':str})\n",
    "df['dest_zipcode'] = zip_correcter(df['dest_zipcode'])\n",
    "df['origin_zipcode'] = zip_correcter(df['origin_zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0a292fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.dropna().sample(num_order, random_state = random_state_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8588c93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['origin_zipcode'] = df2['origin_zipcode'].astype(str)\n",
    "df2['dest_zipcode'] = df2['dest_zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c261534",
   "metadata": {},
   "source": [
    "Creating pickup_midpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9ad2f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns pick_up_midpoint\n",
    "from datetime import datetime\n",
    "df2['pickup_start_date_time'] = df2.apply(lambda row: datetime.strptime(row['pickup_window_start'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['pickup_end_date_time'] = df2.apply(lambda row: datetime.strptime(row['pickup_window_end'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['pickup_midpoint'] = df2.apply(lambda row: row['pickup_start_date_time'] + (row['pickup_end_date_time'] - row['pickup_start_date_time']) / 2,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7d2518",
   "metadata": {},
   "source": [
    "Creating Delivery_midpoint time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "000c0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the columns delivery midpoints\n",
    "df2['delivery_start_date_time'] = df2.apply(lambda row: datetime.strptime(row['delivery_window_start'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['delivery_end_date_time'] = df2.apply(lambda row: datetime.strptime(row['delivery_window_end'], '%m/%d/%Y %H:%M'),axis = 1)\n",
    "df2['delivery_midpoint'] = df2.apply(lambda row: row['delivery_start_date_time'] + (row['delivery_end_date_time'] - row['delivery_start_date_time']) / 2,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d834eae4",
   "metadata": {},
   "source": [
    "Assuming that the drivers start working at 6am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e4456e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mondays = []\n",
    "import datetime\n",
    "#Computing the mondays 6am of the weeks that the jobs are in\n",
    "for ts in df2['pickup_midpoint']:\n",
    "    # convert to datetime object\n",
    "    dt = ts.to_pydatetime()\n",
    "\n",
    "    # get the date and weekday\n",
    "    date = dt.date()\n",
    "    weekday = date.weekday()\n",
    "\n",
    "    # calculate timedelta to previous Monday\n",
    "    days_to_subtract = (7 + weekday) % 7\n",
    "    monday = date - datetime.timedelta(days=days_to_subtract)\n",
    "\n",
    "    # set hour and minute\n",
    "    monday = datetime.datetime.combine(monday, datetime.time(hour=6, minute=0))\n",
    "\n",
    "    # convert back to timestamp object\n",
    "    monday = pd.Timestamp(monday)\n",
    "\n",
    "    mondays.append(monday)\n",
    "\n",
    "mondays  # output: [Timestamp('2023-03-06 06:00:00'),\n",
    "\n",
    "df2['monday_6am'] = mondays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2377d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_arrive(mid_point):\n",
    "    time_available = max(mid_point.weekday()-1, 0)*12 + mid_point.hour-6 + mid_point.minute/60\n",
    "    return time_available\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8a9e1",
   "metadata": {},
   "source": [
    "Computing whether the driver could arrive to the job if they begin driving at 6am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "789295b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the time difference between monday 6am and the pickup_midpoint time\n",
    "df2['driver_home_to_job_midpoint_time_limit'] = df2.apply(lambda row : time_to_arrive(row['pickup_midpoint']),axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc50c83",
   "metadata": {},
   "source": [
    "Importing drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c304d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross merging driver sample and job dataframe\n",
    "md = pd.read_csv('C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/simulated_driver_sample.csv', dtype={'depot_zipcode':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "99b1d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "md['depot_zipcode'] = zip_correcter(md['depot_zipcode'])\n",
    "ds = md.sample(num_driver, random_state = random_state_param)\n",
    "ds['key']=1\n",
    "df2['key']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1db95",
   "metadata": {},
   "source": [
    "Creating terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d193c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning terminals to drivers\n",
    "terminals = []\n",
    "\n",
    "for i in range (0,len(ds)):\n",
    "    terminals.append(str('T'+str(i)))\n",
    "\n",
    "ds['terminals'] = terminals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac2e61",
   "metadata": {},
   "source": [
    "Merging drivers and orders to compute all driver-to-order possibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ba2d8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame = pd.merge(ds,df2, on = 'key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b72f8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips = pd.read_csv('uszips.csv', dtype={'zip':str})\n",
    "zips['zip'] = zip_correcter(zips['zip'])\n",
    "zips['zip'] = zips['zip'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c37b38",
   "metadata": {},
   "source": [
    "Examine how many driver zip codes are not included in the zip code profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e7912aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zips['zip'][zips['zip'].isin(big_frame['depot_zipcode'])]) - len(big_frame['depot_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "beba0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_frame['origin_zipcode'] = big_frame['origin_zipcode'].astype(str)\n",
    "big_frame['dest_zipcode'] = big_frame['dest_zipcode'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a1b52d",
   "metadata": {},
   "source": [
    "Examine how many order zip codes are not included in the zip code profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b3b9383d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#zips['zip'][zips['zip'].isin(big_frame['origin_zipcode'])]\n",
    "len(zips['zip'][zips['zip'].isin(big_frame['origin_zipcode'])]) - len(big_frame['origin_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b8b47ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zips['zip'][zips['zip'].isin(big_frame['dest_zipcode'])]) - len(big_frame['dest_zipcode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "554f437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_frame['dest_zipcode'][~big_frame['dest_zipcode'].isin(zips['zip'])].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ced569a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips.columns = ['zip','depot_lat','depot_lng']\n",
    "bigger_frame = pd.merge(zips,big_frame, left_on = 'zip', right_on = 'depot_zipcode')\n",
    "zips.columns = ['zip','origin_lat','origin_lng']\n",
    "bigger_bigger_frame = pd.merge(zips,bigger_frame, left_on = 'zip', right_on = 'origin_zipcode')\n",
    "zips.columns = ['zip','dest_lat','dest_lng']\n",
    "biggest_frame = pd.merge(zips, bigger_bigger_frame, left_on = 'zip', right_on = 'dest_zipcode')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2068a0",
   "metadata": {},
   "source": [
    "Computing driver to job distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c01eabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['depot_lng'],row['depot_lat'],row['origin_lng'],row['origin_lat']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a6123f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_verification_sample = biggest_frame.sample(300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbb4d5d",
   "metadata": {},
   "source": [
    "Examining the validity of haversine distance. The examination costs time, so let the codes be commented out if not examining. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c35f8d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49ffa747",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['haversine_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['origin_lng'],row['origin_lat'],row['dest_lng'],row['dest_lat']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5be370a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exam = pd.DataFrame((biggest_frame['haversine_distance'].drop_duplicates()-biggest_frame['DispatchMiles'].drop_duplicates())/biggest_frame['DispatchMiles'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f4a281ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13.684155\n",
       "dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exam.dropna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5d628b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_distance_plus'] = biggest_frame['driver_to_job_distance'] + biggest_frame['haversine_distance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fa89572",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['driver_to_job_time'] = biggest_frame['driver_to_job_distance_plus'] .apply(lambda row: my_time(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "201a3f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the feasible 1st jobs. If a job cannot be done on the first wave of driver's after 6am on Monday, the jobs cannot be done\n",
    "first_wave = biggest_frame[biggest_frame['driver_to_job_time'] < biggest_frame['driver_home_to_job_midpoint_time_limit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e7b7b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_wave = first_wave[first_wave['driver_to_job_distance']>0]\n",
    "first_wave = first_wave.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "911d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_to_order = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    driver_to_order[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7315be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_frame['job_to_driver_distance'] = biggest_frame.apply(lambda row: haversine_distance(row['origin_lng'], row['origin_lat'], row['depot_lng'], row['depot_lat']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a97d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_day = []\n",
    "for index, row in df2.iterrows():\n",
    "    if row['delivery_start_date_time'].day != row['delivery_end_date_time'].day:\n",
    "        equal_day.append('1')\n",
    "    else:\n",
    "        equal_day.append('0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d557330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['same_day'] = equal_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d216c81",
   "metadata": {},
   "source": [
    "Examining the computed midpoint time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd3e99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for index, row in df2[df2['same_day']=='1'].iterrows():\n",
    " #   print(row['delivery_start_date_time'], row['delivery_start_date_time'] + (row['delivery_end_date_time'] - row['delivery_start_date_time']) /2, row['delivery_end_date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4f9cc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['delivery_midpoint'] = df2['delivery_start_date_time'] + (df2['delivery_end_date_time'] - df2['delivery_start_date_time']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "de14b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['pickup_midpoint'] = df2['pickup_start_date_time'] + (df2['pickup_end_date_time'] - df2['pickup_start_date_time']) /2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "01acc187",
   "metadata": {},
   "outputs": [],
   "source": [
    "zips.columns = ['zip','origin_lat','origin_lng']\n",
    "df2 = pd.merge(df2, zips, right_on = 'zip', left_on = 'origin_zipcode', how = 'left')\n",
    "zips.columns = ['zip','dest_lat','dest_lng']\n",
    "df2 = pd.merge(df2, zips, right_on = 'zip', left_on = 'dest_zipcode', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "733efbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a3f6f6e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_zipcode</th>\n",
       "      <th>dest_zipcode</th>\n",
       "      <th>pickup_window_start</th>\n",
       "      <th>pickup_window_end</th>\n",
       "      <th>delivery_window_start</th>\n",
       "      <th>delivery_window_end</th>\n",
       "      <th>LineHaulRevenue</th>\n",
       "      <th>DispatchMiles</th>\n",
       "      <th>...</th>\n",
       "      <th>monday_6am</th>\n",
       "      <th>driver_home_to_job_midpoint_time_limit</th>\n",
       "      <th>key</th>\n",
       "      <th>same_day</th>\n",
       "      <th>zip_x</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lng</th>\n",
       "      <th>zip_y</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, order_id, origin_zipcode, dest_zipcode, pickup_window_start, pickup_window_end, delivery_window_start, delivery_window_end, LineHaulRevenue, DispatchMiles, pickup_start_date_time, pickup_end_date_time, pickup_midpoint, delivery_start_date_time, delivery_end_date_time, delivery_midpoint, monday_6am, driver_home_to_job_midpoint_time_limit, key, same_day, zip_x, origin_lat, origin_lng, zip_y, dest_lat, dest_lng]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['order_id'] == 3786037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c00971f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>order_id</th>\n",
       "      <th>origin_zipcode</th>\n",
       "      <th>dest_zipcode</th>\n",
       "      <th>pickup_window_start</th>\n",
       "      <th>pickup_window_end</th>\n",
       "      <th>delivery_window_start</th>\n",
       "      <th>delivery_window_end</th>\n",
       "      <th>LineHaulRevenue</th>\n",
       "      <th>DispatchMiles</th>\n",
       "      <th>...</th>\n",
       "      <th>monday_6am</th>\n",
       "      <th>driver_home_to_job_midpoint_time_limit</th>\n",
       "      <th>key</th>\n",
       "      <th>same_day</th>\n",
       "      <th>zip_x</th>\n",
       "      <th>origin_lat</th>\n",
       "      <th>origin_lng</th>\n",
       "      <th>zip_y</th>\n",
       "      <th>dest_lat</th>\n",
       "      <th>dest_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, order_id, origin_zipcode, dest_zipcode, pickup_window_start, pickup_window_end, delivery_window_start, delivery_window_end, LineHaulRevenue, DispatchMiles, pickup_start_date_time, pickup_end_date_time, pickup_midpoint, delivery_start_date_time, delivery_end_date_time, delivery_midpoint, monday_6am, driver_home_to_job_midpoint_time_limit, key, same_day, zip_x, origin_lat, origin_lng, zip_y, dest_lat, dest_lng]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 26 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[df2['order_id'] == 3786037]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e149f9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index_x', 'order_id_x', 'origin_zipcode_x', 'dest_zipcode_x',\n",
       "       'pickup_window_start_x', 'pickup_window_end_x',\n",
       "       'delivery_window_start_x', 'delivery_window_end_x', 'LineHaulRevenue_x',\n",
       "       'DispatchMiles_x', 'pickup_start_date_time_x', 'pickup_end_date_time_x',\n",
       "       'pickup_midpoint_x', 'delivery_start_date_time_x',\n",
       "       'delivery_end_date_time_x', 'delivery_midpoint_x', 'monday_6am_x',\n",
       "       'driver_home_to_job_midpoint_time_limit_x', 'key', 'same_day_x',\n",
       "       'zip_x_x', 'origin_lat_x', 'origin_lng_x', 'zip_y_x', 'dest_lat_x',\n",
       "       'dest_lng_x', 'index_y', 'order_id_y', 'origin_zipcode_y',\n",
       "       'dest_zipcode_y', 'pickup_window_start_y', 'pickup_window_end_y',\n",
       "       'delivery_window_start_y', 'delivery_window_end_y', 'LineHaulRevenue_y',\n",
       "       'DispatchMiles_y', 'pickup_start_date_time_y', 'pickup_end_date_time_y',\n",
       "       'pickup_midpoint_y', 'delivery_start_date_time_y',\n",
       "       'delivery_end_date_time_y', 'delivery_midpoint_y', 'monday_6am_y',\n",
       "       'driver_home_to_job_midpoint_time_limit_y', 'same_day_y', 'zip_x_y',\n",
       "       'origin_lat_y', 'origin_lng_y', 'zip_y_y', 'dest_lat_y', 'dest_lng_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = pd.merge(df2, df2, on = 'key')\n",
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e35e12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['inter_job_distance'] = df3.apply(lambda row: haversine_distance(row['dest_lng_x'],row['dest_lat_x'],row['origin_lng_y'],row['origin_lat_y']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3d5d4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3[df3['inter_job_distance'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5a009403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3['inter_job_distance'].apply(lambda row: my_time(row))\n",
    "inter_job_time = []\n",
    "for index, row in df3.iterrows():\n",
    "    inter_job_time.append(my_time(row['inter_job_distance']))\n",
    "df3['inter_job_time'] = inter_job_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bed9f5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['inter_job_time_limit'] = (df3['pickup_midpoint_y'] - df3['delivery_midpoint_x']).astype('timedelta64[h]') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3b39b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3[df3['inter_job_time'] < df3['inter_job_time_limit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99188aeb",
   "metadata": {},
   "source": [
    " ## Creating arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9986896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f51ff",
   "metadata": {},
   "source": [
    "Purple arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "724853dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_wave = first_wave.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6c3eea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_out_arcs = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    purple_out_arcs[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1a14dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_out_flow_arcs = {}\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['driver_id']),str(row['terminals']), str(row['order_id']))\n",
    "    value = my_time(row['driver_to_job_distance_plus'])\n",
    "    purple_out_flow_arcs[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ca3d1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_in_arcs = {}\n",
    "\n",
    "for i in range(0,len(first_wave)):\n",
    "    purple_in_arcs[(str(str(first_wave['order_id'][i])),first_wave['terminals'][i])] = my_time(first_wave[\"driver_to_job_distance\"][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0d8f7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "purple_in_flow_arcs = {}\n",
    "\n",
    "for index, row in first_wave.iterrows():\n",
    "    key = (str(row['driver_id']), str(row['order_id']), str(row['terminals']))\n",
    "    value = my_time(row[\"driver_to_job_distance\"])\n",
    "    purple_in_flow_arcs[key] = value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a693ae",
   "metadata": {},
   "source": [
    "green arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "048e3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0e05257d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4['second_job_distance'] = df4.apply(lambda row: haversine_distance(row['dest_lng_y'], row['dest_lat_y'], row['origin_lng_y'], row['origin_lat_y']),axis = 1)\n",
    "df5 = df4[df4['second_job_distance'] > 0]\n",
    "df5['second_job_time'] = df5['second_job_distance'].apply(lambda row: my_time(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bb70349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['green_arc_time'] = df5['second_job_time']+df5['inter_job_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "423fb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.reset_index()\n",
    "green_arcs = {}\n",
    "\n",
    "for i in range(0,len(df5)):\n",
    "    green_arcs[str(df5['order_id_x'][i]),str(df5[\"order_id_y\"][i])] = df5[\"green_arc_time\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3805f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5[['order_id_x','order_id_y','green_arc_time']]\n",
    "df7 = first_wave[['driver_id','order_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dc25f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = pd.merge(df6,df7,left_on = 'order_id_x', right_on = 'order_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "f9980e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8 = df8.reset_index()\n",
    "green_flow_arcs = {}\n",
    "\n",
    "for i in range(0,len(df8 )):\n",
    "    green_flow_arcs[str(df8['driver_id'][i]), str(df8['order_id_x'][i]),str(df8[\"order_id_y\"][i])] = df8[\"green_arc_time\"][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb2dd9c",
   "metadata": {},
   "source": [
    "terminals, drivers, and orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "5eee491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311218\n",
      "31014\n",
      "8933\n",
      "8933\n",
      "8933\n",
      "8933\n"
     ]
    }
   ],
   "source": [
    "print(len(green_flow_arcs))\n",
    "print(len(green_arcs))\n",
    "print(len(purple_out_flow_arcs))\n",
    "print(len(purple_out_arcs))\n",
    "print(len(purple_in_arcs))\n",
    "print(len(purple_in_flow_arcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f8622ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_arcs = {}\n",
    "all_arcs.update(purple_out_arcs)\n",
    "all_arcs.update(purple_in_arcs)\n",
    "all_arcs.update(green_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66bf6888",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_arcs = {}\n",
    "flow_arcs.update(purple_out_flow_arcs)\n",
    "flow_arcs.update(purple_in_flow_arcs)\n",
    "flow_arcs.update(green_flow_arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7a164b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_revenues = {}\n",
    "\n",
    "for i in range(0,len(df2)):\n",
    "    jobs_revenues[str(df2['order_id'][i])] = df2[\"LineHaulRevenue\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8b9ce7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "drivers = list(ds['driver_id'])\n",
    "jobs = list(df2['order_id'].astype(str))\n",
    "nodes = terminals + jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7ebedcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "order_data_set = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2c59c476",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_materials = (terminals, drivers, jobs, nodes, jobs_revenues, all_arcs, flow_arcs, order_data_set, first_wave,ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cf834b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T0', 'T1', 'T2', 'T3', 'T4', 'T5']\n",
      "['Driver286', 'Driver223', 'Driver311', 'Driver458', 'Driver378', 'Driver247']\n",
      "['3305', '476', '4911', '9245', '1438', '3850']\n",
      "['T0', 'T1', 'T2', 'T3', 'T4', 'T5']\n",
      "{'3305': 2156.820500831456, '476': 2748.9309733452424, '4911': 3000.115856589595, '9245': 1287.4644767452107, '1438': 2383.823628614321, '3850': 2689.333683073839}\n",
      "{('T17', '2363'): 28.437503646537525, ('T29', '2363'): 27.330132230242057, ('T22', '2363'): 23.613028522995, ('T20', '2363'): 26.15496421823642, ('T25', '2363'): 27.20856293091873, ('T0', '2363'): 34.766723710145314}\n",
      "{('Driver41', 'T17', '2363'): 28.437503646537525, ('Driver331', 'T29', '2363'): 27.330132230242057, ('Driver91', 'T22', '2363'): 23.613028522995, ('Driver228', 'T20', '2363'): 26.15496421823642, ('Driver344', 'T25', '2363'): 27.20856293091873, ('Driver286', 'T0', '2363'): 34.766723710145314}\n",
      "   index  order_id origin_zipcode dest_zipcode pickup_window_start  \\\n",
      "0   3305      3305          35806        57744    01/30/2023 11:56   \n",
      "1    476       476          93737        46555    02/03/2023 06:23   \n",
      "2   4911      4911          20670        74463    02/03/2023 21:14   \n",
      "3   9245      9245          53501        29625    02/04/2023 06:43   \n",
      "4   1438      1438          54739        19131    02/02/2023 22:11   \n",
      "5   3850      3850          35643        53069    02/01/2023 06:36   \n",
      "\n",
      "  pickup_window_end delivery_window_start delivery_window_end  \\\n",
      "0  01/30/2023 17:15      02/02/2023 00:58    02/02/2023 05:00   \n",
      "1  02/03/2023 20:17      02/06/2023 22:16    02/07/2023 14:38   \n",
      "2  02/04/2023 05:06      02/07/2023 03:14    02/07/2023 14:23   \n",
      "3  02/04/2023 17:08      02/07/2023 07:05    02/07/2023 04:07   \n",
      "4  02/02/2023 22:51      02/06/2023 17:27    02/07/2023 05:21   \n",
      "5  02/01/2023 16:49      02/03/2023 16:39    02/03/2023 21:31   \n",
      "\n",
      "   LineHaulRevenue  DispatchMiles  ...          monday_6am  \\\n",
      "0      2156.820501            233  ... 2023-01-30 06:00:00   \n",
      "1      2748.930973             53  ... 2023-01-30 06:00:00   \n",
      "2      3000.115857            415  ... 2023-01-30 06:00:00   \n",
      "3      1287.464477            114  ... 2023-01-30 06:00:00   \n",
      "4      2383.823629            365  ... 2023-01-30 06:00:00   \n",
      "5      2689.333683            487  ... 2023-01-30 06:00:00   \n",
      "\n",
      "  driver_home_to_job_midpoint_time_limit key same_day  zip_x origin_lat  \\\n",
      "0                               8.583333   1        0  35806   34.76615   \n",
      "1                              43.333333   1        1  93737   36.75358   \n",
      "2                              43.166667   1        0  20670   38.28240   \n",
      "3                              53.916667   1        0  53501   42.60484   \n",
      "4                              40.516667   1        1  54739   44.86177   \n",
      "5                              17.700000   1        0  35643   34.66882   \n",
      "\n",
      "  origin_lng  zip_y  dest_lat   dest_lng  \n",
      "0  -86.68324  57744  43.77730 -103.02415  \n",
      "1 -119.64560  46555  41.32858  -85.68833  \n",
      "2  -76.42031  74463  35.76943  -95.54843  \n",
      "3  -89.07165  29625  34.55577  -82.76294  \n",
      "4  -91.70097  19131  39.98865  -75.21835  \n",
      "5  -87.20707  53069  43.11310  -88.43094  \n",
      "\n",
      "[6 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "for obj in model_materials[:8]:\n",
    "    if isinstance(obj, dict):\n",
    "        first_five_items = {k: obj[k] for k in list(obj.keys())[:6]}\n",
    "    else:\n",
    "        first_five_items = obj[:6]\n",
    "    print(first_five_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "bbafdaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/jiadiz/Desktop/PGT Trucking/initial model/Github/model_materials.pkl', 'wb') as f:\n",
    "    pickle.dump(model_materials, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1809f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
